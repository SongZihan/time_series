{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_data = pd.read_csv('./气候数据集/DailyDelhiClimateTrain.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3 4]\n",
      "[5 6 7 8 9]\n",
      "[10 11 12 13 14]\n",
      "[15 16 17 18 19]\n",
      "[20 21 22 23 24]\n"
     ]
    }
   ],
   "source": [
    "# 生成1-1000的tf数组（可迭代对象）\n",
    "range_ds = tf.data.Dataset.range(1002)\n",
    "# 通过batch形式获取数据,drop_remainder 是剪掉尾巴\n",
    "batchs = range_ds.batch(5,drop_remainder=True)\n",
    "# take(4)代表只取五组数据\n",
    "for i in batchs.take(5):\n",
    "    print(i.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 当需要一步一步获取数据和标签的时候"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]  =>  4\n",
      "[5 6 7 8]  =>  9\n",
      "[10 11 12 13]  =>  14\n"
     ]
    }
   ],
   "source": [
    "def dense_1_step(batch):\n",
    "  # Shift features and labels one step relative to each other.\n",
    "  # 切分batch数组以指定的形式返回\n",
    "    return batch[:-1], batch[-1]\n",
    "\n",
    "predict_dense_1_step = batchs.map(dense_1_step)\n",
    "\n",
    "for features, label in predict_dense_1_step.take(3):\n",
    "    print(features.numpy(), \" => \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 当需要用类似windows移动的方式获取数据的时候"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_window_dataset(ds, window_size=5, shift=1, stride=1):\n",
    "    \"\"\"\n",
    "    ds: 数据集\n",
    "    window_size: 窗口的尺寸\n",
    "    shift: 窗口的移动单位\n",
    "    stride: 取的数据的间隔\n",
    "    \"\"\"\n",
    "    windows = ds.window(window_size+1, shift=shift, stride=stride)\n",
    "\n",
    "    def sub_to_batch(sub):\n",
    "        return sub.batch(window_size+1, drop_remainder=True)\n",
    "\n",
    "    windows = windows.flat_map(sub_to_batch)\n",
    "    return windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 2 3]  =>  4\n",
      "[1 2 3 4]  =>  5\n",
      "[2 3 4 5]  =>  6\n",
      "[3 4 5 6]  =>  7\n",
      "[4 5 6 7]  =>  8\n"
     ]
    }
   ],
   "source": [
    "windows_dataset = make_window_dataset(range_ds)\n",
    "# 获取窗口的batch数据集,然后使用lambda函数获取标签\n",
    "process_windows_dataset = windows_dataset.map(dense_1_step)\n",
    "for features, label in process_windows_dataset.take(5):\n",
    "    print(features.numpy(), \" => \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 当需要对数据进行随机采样"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 99 100 101 102]  =>  103\n",
      "[148 149 150 151]  =>  152\n",
      "[126 127 128 129]  =>  130\n",
      "[155 156 157 158]  =>  159\n",
      "[ 8  9 10 11]  =>  12\n"
     ]
    }
   ],
   "source": [
    "windows_dataset = make_window_dataset(range_ds)\n",
    "# 对batch数据集进行shuffle操作\n",
    "windows_dataset = windows_dataset.shuffle(200)\n",
    "# 获取标签\n",
    "windows_dataset = windows_dataset.map(dense_1_step)\n",
    "\n",
    "for features, label in windows_dataset.take(5):\n",
    "    print(features.numpy(), \" => \", label.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 当需要输入模型时"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[144 145 146 147]\n",
      " [ 77  78  79  80]\n",
      " [ 47  48  49  50]\n",
      " [ 91  92  93  94]\n",
      " [140 141 142 143]\n",
      " [ 50  51  52  53]]  =>  [148  81  51  95 144  54]\n",
      "[[176 177 178 179]\n",
      " [ 16  17  18  19]\n",
      " [201 202 203 204]\n",
      " [108 109 110 111]\n",
      " [ 73  74  75  76]\n",
      " [ 71  72  73  74]]  =>  [180  20 205 112  77  75]\n",
      "[[198 199 200 201]\n",
      " [107 108 109 110]\n",
      " [  7   8   9  10]\n",
      " [ 68  69  70  71]\n",
      " [ 85  86  87  88]\n",
      " [ 99 100 101 102]]  =>  [202 111  11  72  89 103]\n",
      "[[165 166 167 168]\n",
      " [ 10  11  12  13]\n",
      " [ 43  44  45  46]\n",
      " [119 120 121 122]\n",
      " [138 139 140 141]\n",
      " [ 66  67  68  69]]  =>  [169  14  47 123 142  70]\n",
      "[[ 56  57  58  59]\n",
      " [167 168 169 170]\n",
      " [185 186 187 188]\n",
      " [103 104 105 106]\n",
      " [126 127 128 129]\n",
      " [ 60  61  62  63]]  =>  [ 60 171 189 107 130  64]\n"
     ]
    }
   ],
   "source": [
    "windows_dataset = make_window_dataset(range_ds)\n",
    "# 对batch数据集进行shuffle操作\n",
    "windows_dataset = windows_dataset.shuffle(200)\n",
    "# 获取标签\n",
    "windows_dataset = windows_dataset.map(dense_1_step)\n",
    "# 再次batch，这次batch是将已经分好标签的数据进行打包\n",
    "\"\"\"\n",
    "tf.data API 通过 tf.data.Dataset.prefetch 转换提供了一种软件流水线机制，该机制可用于将生成数据的时间和使用数据的时间分离开。\n",
    "具体而言，该转换使用后台线程和内部缓冲区，以便在请求元素之前从输入数据集中预取这些元素\n",
    "因此，为了实现上图所示的流水线效果，您可以将 prefetch() 作为最终转换添加到数据集流水线中（如果单步训练使用 n 个元素，则添加 prefetch(n)）\n",
    "\"\"\"\n",
    "windows_dataset = windows_dataset.batch(6).prefetch(1)\n",
    "for features, label in windows_dataset.take(5):\n",
    "    print(features.numpy(), \" => \", label.numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
